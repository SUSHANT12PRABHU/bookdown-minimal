[["index.html", "Sentiment Analysis Processing and Visualization Tutorial 1 googleVis in R 1.1 Introducing googleVis 1.2 Why use googleVis ? 1.3 googleVis Rendering &amp; Interaction 1.4 Use googleVis in RStudio", " Sentiment Analysis Processing and Visualization Tutorial Lylybell Teran 1 googleVis in R Sushant Prabhu and Kiyan Mohebbizadeh 1.1 Introducing googleVis GoogleVis is a package in R that allows users of R to use the Google Charts API. The interface between R and Google Charts allows users to access Google Charts’ interactive charts. googleVis allows users to use the data in R data frames to create Google Charts without uploading the data onto Google. Demonstrating using googleVis Library - Installation and Usage install.packages(&#39;googleVis&#39;) library(googleVis) 1.2 Why use googleVis ? googleVis package allows users to create interactive visualizations which R’s most popular visualization package (ggplot) does not allow. Although there are packages that work in conjunction with ggplot to make interactive visualizations, googleVis offers a holistic package that allows for some unique and interactive visualizations. By using Google Charts, one is able to create a wide variety of visualizations ranging from typical bar and line graphs to mapping and timeline charts all from one package. The visualizations created by googleVis add a level of interest to the consumer due to their interactive layer and viewers are able to gather specific bits of information by hovering over and clicking values in the visualizations. This not only allows for increased aesthetics, but also more information being transferred to the viewers. 1.3 googleVis Rendering &amp; Interaction The output of googleVis can either be embedded into an HTML file or read dynamically. These visualizations are most often rendered online and in a web format. Therefore, a browser and internet connection are required to view the interactive version of the output compared to ggplot For use in R, googleVis allows a user to render as a Shiny file that then allows a preview with interaction within R. This is used to preview a chart before a final render. googleVis is a package in R that allows users of R to use the Google Charts API. The interface between R and Google Charts allows users to access Google Charts’ interactive charts. googleVis allows users to use the data in R data frames to create Google Charts without uploading the data onto Google. 1.3.1 Basic Graphs (Line, Bar, Combo) df = data.frame(pet=c(&#39;cat&#39;, &#39;dog&#39;, &#39;hamster&#39;, &#39;snake&#39;), food_cost_monthly=c(50, 100, 10, 40), medical_cost_monthly=c(30, 60, 5, 50)) Line &lt;- gvisLineChart(df) Bar &lt;- gvisBarChart(df) Column &lt;- gvisColumnChart(df) SteppedArea &lt;- gvisSteppedAreaChart(df, xvar=&quot;pet&quot;, yvar=c(&quot;food_cost_monthly&quot;, &quot;medical_cost_monthly&quot;), options=list(isStacked=TRUE)) Combo &lt;- gvisComboChart(df, xvar=&quot;pet&quot;, yvar=c(&quot;food_cost_monthly&quot;, &quot;medical_cost_monthly&quot;), options=list(seriesType=&quot;bars&quot;, series=&#39;{1: {type:&quot;line&quot;}}&#39;)) plot(Line) plot(Bar) plot(Column) plot(SteppedArea) plot(Combo) The above charts are best used in comparisons between groups. As seen in the examples, there are comparisons between costs of owning different pets. The line graph shows how different variables flow within and among groups. The audience is able to determine within group trends by seeing where lines intersect within each group. Showing the up and down trends of these variables with lines between groups allows us to make comparisons among the various groups with clarity.By organizing the variables in a certain way, one is able to get a sense of population trends. The bar and column chart are essentially the same just rotated on an axis. They allow for great in group comparisons as well as comparisons among groups. However, These charts are best used for in-group comparisons. Combo charts are great for multiple variable comparisons and allow the user to get the best of both worlds. by carefully selecting which variables are represented in bars and which ones are lines, the user is able to best show the relationship within groups and trends of the population. 1.3.2 googleVis Histogram Chart df &lt;- iris Histogram &lt;- gvisHistogram(data.frame(Sepal_Width = df$Sepal.Width)) plot(Histogram) The histogram allows users to represent the distribution of one particular group or variable by showing the frequency of the particular group or variable within a range. The charts by googleVis have an advantage over regular histograms because almost no histogram allows or recommends specific information regarding the counts at different points in the visualization, however, with googleVis the audience can not only look at the distribution but access specific metrics through interaction as well. 1.3.3 googleVis Alluvial/Sankey Chart df &lt;- data.frame(From=c(rep(&quot;Math&quot;,3), rep(&quot;Science&quot;, 3)), To=c(rep(c(&#39;Lunch&#39;, &#39;Art&#39;, &#39;Music&#39;),2)), Weight=c(17,15,13,5,12,8)) Alluvial &lt;- gvisSankey(df, from=&quot;From&quot;, to=&quot;To&quot;, weight=&quot;Weight&quot;) plot(Alluvial) Alluvial charts best show the movement of the sample or population among different variables. In the example above the movement of students within a school from class to class is represented. This visualization can be helpful with data that has an ordinal and timeline specific values. With googleVis, the audience is exposed to the general trends with a clean looking chart as well as the specifics of the graph through interaction. 1.3.4 googleVis Geographic Chart df = data.frame(country=c(&#39;US&#39;, &#39;CN&#39;, &#39;BR&#39;, &#39;IS&#39;, &#39;RU&#39;, &#39;TH&#39;, &#39;TR&#39;, &#39;ID&#39;, &#39;MX&#39;, &#39;IR&#39; ), incarceration_rate = c(2068800, 1690000, 811707, 478600, 471490, 309282, 291198, 266259, 220866, 189000)) G &lt;- gvisGeoChart(df, locationvar = &quot;country&quot;, colorvar = &quot;incarceration_rate&quot;, options=list( gvis.editor=&quot;Edit the Geo Chart !&quot;)) plot(G) Map visualizations by googleVis are incredibly easy to create and manipulate. They are useful for comparing different geographic areas to each other. googleVis automatically color scales the values and the interaction allows the map to be simple and clean, but get specific values when hovering over a particular geographic area. 1.3.5 googleVis Gauge Chart temperature &lt;- data.frame(city=c(&#39;Las Vegas&#39;, &#39;Los Angeles&#39;, &#39;Pheonix&#39;, &#39;Dallas&#39;, &#39;Houston&#39;, &#39;Miami&#39;), temp=c(115, 103, 120, 110, 112, 101)) Gauge &lt;- gvisGauge(temperature, options=list(min=0, max=150, greenFrom=0, greenTo=50, yellowFrom=50, yellowTo=100, redFrom=100, redTo=150, width=400, height=300)) plot(Gauge) The gauge charts are not interactive, however they do offer a unique way to model data that is always within a certain range. For example, temperatures, speeds, pressure, etc. This chart allows for quick comparison between groups and aesthetic value to any presentation. 1.3.6 googleVis Tabular Chart ## Tabular Data Un-Paged Population_Tabular_Unpaged &lt;- gvisTable(Population[1:30,], formats=list(Population=&quot;#,###&quot;,&#39;% of World Population&#39;=&#39;#.#%&#39;)) plot(Population_Tabular_Unpaged) ## Tabular Data Paged Population_Tabular_paged &lt;- gvisTable(Population[1:30,], formats=list(Population=&quot;#,###&quot;,&#39;% of World Population&#39;=&#39;#.#%&#39;), options=list(page=&#39;enable&#39;, height=&#39;automatic&#39;, width=&#39;automatic&#39;)) plot(Population_Tabular_paged) The data formatted as a table can be paged and sorted. It has a flexible option to select single rows either with the keyboard or the mouse. It also powers sorting on rows across all dimensions in the columns of the dataset. The navigation through paged tabular information is smooth and simple. 1.3.7 googleVis Tree Map Chart Country_Tree &lt;- gvisTreeMap(Regions, &quot;Region&quot;, &quot;Parent&quot;, &quot;Val&quot;, &quot;Fac&quot;, options=list(width=800, height=500, fontSize=15, minColor=&#39;#cfe2f3&#39;,midColor=&#39;#6fa8dc&#39;,maxColor=&#39;#0b5394&#39;, headerHeight=10,fontColor=&#39;black&#39;,showScale=TRUE)) plot(Country_Tree) The googleVis tree map is a visual representation of a data tree, where each node has 0 or more children, and 1 parent barring the root node. One can specify how many levels to display simultaneously, and optionally to display deeper levels. One can move down the tree when the person left-clicks a node, and moves back up the tree when the person right-clicks the graph.The total size of the graph is determined by the size of the elements contained in the graph. This googleVis tree map chart captures the relative sizes of data categories, that helps for quick insight of the datapoints that are bigger contributors to each category. Color helps scrutinize datapoints that are underperforming / overperforming) compared to their siblings from the same category. 1.3.8 googleVis Annotation Chart Stock_Annotation &lt;- gvisAnnotationChart(Stock, datevar=&quot;Date&quot;,numvar=&quot;Value&quot;, idvar=&quot;Device&quot;, titlevar=&quot;Title&quot;, annotationvar=&quot;Annotation&quot;, options=list(displayAnnotations=TRUE, chart=&quot;{chartArea:{backgroundColor:&#39;#ebf0f7&#39;}}&quot;, legendPosition=&#39;newRow&#39;,width=800, height=450, scaleColumns=&#39;[0,1]&#39;,scaleType=&#39;allmaximized&#39;)) plot(Stock_Annotation) Annotation charts are useful, interactive time series like line charts that enable annotations.These annotated charts are leveraged to highlight specific data or value-add the contextual notes within the visualization. To answer the “so what ?” kind of questions, such well defined annotations highlight the significance of data in the chart, with keen detail in the textual description / annotation. One can also slice through the interactive timeline chart to look for a snapshot of data which is aesthetically pleasing and also provides great detail insights within the same visualization. These annotation charts are SVG (scalable vector graphics) /VML (vector graphics rendering ). 1.3.9 googleVis Calendar Chart Calendar_Temp &lt;- gvisCalendar(Cairo, datevar=&quot;Date&quot;, numvar=&quot;Temp&quot;, options=list(title=&quot;Cairo&#39;s variation in Daily temperature&quot;,height=400,width=1000, calendar=&quot;{yearLabel: { fontName:&#39;sans-serif&#39;, fontSize: 20, color: &#39;black&#39;, bold: true}, cellSize: 10,cellColor:{stroke: &#39;black&#39;, strokeOpacity: 0.2}, focusedCellColor: {stroke:&#39;red&#39;}}&quot;), chartid=&quot;Calendar&quot;) plot(Calendar_Temp) The googleVis calendar chart is a definitive visualization that can be used to show activity over the course of a longer duration of time, example in months or years or decades. One can illustrate the variation of 1 quantity depending on the days of the given week, or trends over the timeline period. Such calendar charts demonstrate data records, or events, on a daily, weekly, monthly, yearly calendar. It is highly interactive and one can view the value on hovering on any particular time of the entire timeperiod. 1.3.10 googleVis Timeline Chart Position_Timeline_Data &lt;- data.frame(Position=c(rep(&quot;President&quot;, 4), rep(&quot;Vice&quot;, 4)), Name=c(&quot;William Clinton&quot;,&quot;George Bush&quot;, &quot;Barack Obama&quot;, &quot; Donald Trump&quot;, &quot; Albert Gore&quot;,&quot;Dick Cheney&quot;, &quot;Biden, Jr.&quot;, &quot;Michael Pence&quot;), start=as.Date(x=rep(c(&quot;1993-01-20&quot;,&quot;2001-01-20&quot;, &quot;2009-01-20&quot;,&quot;2017-01-20&quot;),2)), end=as.Date(x=rep(c(&quot;2001-01-20&quot;,&quot;2009-01-20&quot;, &quot;2017-01-20&quot;, &quot;2021-01-20&quot;),2))) Timeline &lt;- gvisTimeline(data=Position_Timeline_Data, rowlabel=&quot;Name&quot;, barlabel=&quot;Position&quot;, start=&quot;start&quot;, end=&quot;end&quot;, options=list(timeline=&quot;{groupByRowLabel:false}&quot;, backgroundColor=&#39;#e3f4ff&#39;, height=400,colors=&quot;[&#39;#0e407d&#39;, &#39;#78b2ff&#39;, &#39;#3737ab&#39;]&quot;)) plot(Timeline) This googleVis Timeline chart is a great and fascinating way of visualizing the different dates / events. Here is an example, showing duration of Presidents &amp; Vice Presidents / Sessions of Congress over the timeline period. The exact times and durations are given when one interactively hovers over the bars. These timeline charts are versatile visuals for illustrating a sequence of events chronologically. It provides an amazing aid to conceptualize event sequences / processes to gain valuable insights, sometimes maybe summarize historical events, or time frame of minutes, hours, years or datewise. 1.3.11 googleVis Gantt Chart daysToMilliseconds &lt;- function(days){days * 24 * 60 * 60 * 1000} dat &lt;- data.frame(taskID = c(&quot;PS&quot;, &quot;EDA&quot;, &quot;R&quot;, &quot;ML&quot;, &quot;DP&quot;), taskName = c(&quot;Identify Problem Statement&quot;, &quot;EDA Analysis&quot;, &quot;Research&quot;, &quot;Machine Learning Modelling&quot;, &quot;Data Preprocessing&quot;), resource = c(NA, &quot;write&quot;, &quot;write&quot;, &quot;complete&quot;, &quot;write&quot;), start = c(as.Date(&quot;2022-10-01&quot;), NA, as.Date(&quot;2022-10-02&quot;), as.Date(&quot;2022-10-08&quot;), NA), end = as.Date(c(&quot;2022-10-04&quot;, &quot;2022-10-08&quot;, &quot;2022-10-08&quot;, &quot;2022-10-13&quot;, &quot;2022-10-05&quot;)), duration = c(NA, daysToMilliseconds(c(3, 1, 1, 1))), percentComplete = c(100, 25, 20, 0, 100), dependencies = c(NA, &quot;PS, DP&quot;, NA, &quot;EDA&quot;, &quot;PS&quot;)) Gantt_Tasks &lt;- gvisGantt(dat, taskID = &quot;taskID&quot;,taskName = &quot;taskName&quot;,resource = &quot;resource&quot;, start = &quot;start&quot;,end = &quot;end&quot;,duration = &quot;duration&quot;,percentComplete = &quot;percentComplete&quot;, dependencies = &quot;dependencies&quot;, options = list(height = 300, gantt = &quot;{criticalPathEnabled:true,innerGridHorizLine: { stroke: &#39;#e3f4ff&#39;,strokeWidth: 2},innerGridTrack: {fill: &#39;#e8f3fa&#39;},innerGridDarkTrack: {fill: &#39;#c7e9ff&#39;},labelStyle: {fontName: &#39;sans-serif&#39;,fontSize: 16}}&quot;)) plot(Gantt_Tasks) googleVis Gantt charts would help teams to plan work around deadlines and allocate resources efficiently. Project planners also leverage Gantt charts to maintain a bird’s eye high level view of projects and track them. These depict the relationship between the start and end dates of tasks, milestones, and dependent tasks for each of them over the entire timeline of the project. This Gantt chart illustrates the breakdown of a project into its component tasks very effectively. 1.3.12 googleVis Merging Charts Geographic &lt;- gvisGeoChart(Exports, locationvar=&quot;Country&quot;,colorvar=&quot;Profit&quot;, options=list(width=400, height=200)) Tabular &lt;- gvisTable(Exports, options=list(width=400, height=400)) Merged_Charts &lt;- gvisMerge(Geographic, Tabular, horizontal=FALSE, tableOptions=&quot;bgcolor=\\&quot;#7cdeb5\\&quot;&quot;) plot(Merged_Charts) googleVis Merge chart provides the flexibility of merging two gvis-objects, either next or below each other into one gvis-object. These objects are arranged in a HTML table format. The multiples charts view allows to split up the individual charts Bar, Column, Line or Geographic, Tabular etc. charts into multiple charts, separated. There are numerous use cases like showing your product sales per region and then providing more information about it. It gives a lot of flexibility in the report creation and delivery aesthetically. 1.4 Use googleVis in RStudio Using googleVis in RStudio is straightforward. By default, the RStudio renders the charts in a new webpage - plot(Chart) On the other hand, to view it within RStudio, &gt; To View in RStudio Viewer just use to view it locally plot(Chart, browser=rstudioapi::viewer) To Knit the Rmd Markdown file to HTML, to perform the following command set the Chunk option results to asis with {r ChartExample, results='asis', tidy=FALSE} and plot(Chart, 'chart') 1.4.1 googleVis References Documentation Google Charts Demo Paper CRAN-Stable Version Thank you for learning googleVis with us ! # library(knitr) # library(tinytex) "],["sentiment-analysis-tutorial.html", "2 Sentiment Analysis Tutorial 2.1 What is Sentiment Analysis? 2.2 Case Study: Performing Sentiment Analysis on Novel 2.3 Pre-processing Data: Tidy-Text 2.4 Most Common Words 2.5 Visualizations 2.6 Summary 2.7 References", " 2 Sentiment Analysis Tutorial In this tutorial we will learn how to convert to tidy data, conduct sentiment analysis, and visualize results using R. The purpose of sentiment analysis model is to categorize words based on their sentiments such as positive, negative, and/or its magnitude. We will use the following packages in this tutorial: # The following packages must first be installed using the the command: install.packages() library(tidyr) library(tidytext) # text-mining library(dplyr) # data manipulation library(stringr) # facilitates strings manipulations library(tibble) # reimaging of dataframes library(ggplot2) # visualizations library(textdata) # includes various sentiment lexicons and labeled text data sets 2.1 What is Sentiment Analysis? Sentiment Analysis defines the process of extracting and evaluating the nature of opinion in documents, websites, social media, etc. These opinions are then classified based on a metric where they can be binary (positive or negative) or they can be classified into a multitude of classes (happy, sad, angry, etc.). 2.1.1 Sentiment Lexicons Sentiment lexicons refers to dictionaries that exist for evaluating text based on emotion/opinion. The tidytext package contains three sentiment lexicons in the sentiments dataset. sentiments ## # A tibble: 6,786 × 2 ## word sentiment ## &lt;chr&gt; &lt;chr&gt; ## 1 2-faces negative ## 2 abnormal negative ## 3 abolish negative ## 4 abominable negative ## 5 abominably negative ## 6 abominate negative ## 7 abomination negative ## 8 abort negative ## 9 aborted negative ## 10 aborts negative ## # … with 6,776 more rows The following are the three lexicons that are based on unigrams (single words) that are in English. The AFFIN lexicon uses a scoring system from -5 to 5 to assign a word with negative scores indicating negative sentiment and positive scores indicating positive sentiment. The bing lexicon uses a binary system where words are categorized as either positive or negative. The nrc lexicon has 10 categories that include positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust. Use the function get_sentiment() to get a specific sentiment lexicon. AFFIN from Finn Årup Nielsen bing from Bing Liu and collaborators nrc from Saif Mohammad and Peter Turney # to see the individual lexicons get_sentiments(&quot;afinn&quot;) ## # A tibble: 2,477 × 2 ## word value ## &lt;chr&gt; &lt;dbl&gt; ## 1 abandon -2 ## 2 abandoned -2 ## 3 abandons -2 ## 4 abducted -2 ## 5 abduction -2 ## 6 abductions -2 ## 7 abhor -3 ## 8 abhorred -3 ## 9 abhorrent -3 ## 10 abhors -3 ## # … with 2,467 more rows get_sentiments(&quot;bing&quot;) ## # A tibble: 6,786 × 2 ## word sentiment ## &lt;chr&gt; &lt;chr&gt; ## 1 2-faces negative ## 2 abnormal negative ## 3 abolish negative ## 4 abominable negative ## 5 abominably negative ## 6 abominate negative ## 7 abomination negative ## 8 abort negative ## 9 aborted negative ## 10 aborts negative ## # … with 6,776 more rows get_sentiments(&quot;nrc&quot;) ## # A tibble: 13,872 × 2 ## word sentiment ## &lt;chr&gt; &lt;chr&gt; ## 1 abacus trust ## 2 abandon fear ## 3 abandon negative ## 4 abandon sadness ## 5 abandoned anger ## 6 abandoned fear ## 7 abandoned negative ## 8 abandoned sadness ## 9 abandonment anger ## 10 abandonment fear ## # … with 13,862 more rows 2.2 Case Study: Performing Sentiment Analysis on Novel We will be analyzing the Charles Darwin book entitled “The Origin of Species.” We will clean (convert to lower case, remove white spaces, and remove stop words) and reform the data into a dataframe using the dpylr, string, and tibble packages. This process will facilitate the analysis of the text. Using the readRDS() from the base R package to write a single R object to a file, and to restore it. The parameters take in the following URL: https://slcladal.github.io/data/origindarwin.rda darwin &lt;- base::readRDS(url(&quot;https://slcladal.github.io/data/origindarwin.rda&quot;, &quot;rb&quot;)) 2.3 Pre-processing Data: Tidy-Text Before applying sentiment analysis, we will pre-process the data by cleaning and transforming it to allow for sentiment analysis application. The following text cleaning techniques were applied to the text to get rid of unnecessary characters or words that may interupt our sentiment analysis. The txtclean() function was created to clean the data by invoking the following: Convert all words to UTF - 8 Convert all words to lower case Collapse paragraphs into single text Remove white spaces Split into individual words Convert to tabular data Remove predefined stop words Remove symbols The tidytext package will allow us to perform efficient text analysis on our data. We will convert the text of our novel into a tidy format using unnest_tokens() function. Tidy data has the following structure: Each variable is a column Each observation is a row Each type of observational unit is a table # process text data using txtclean() darwin_data &lt;- txtclean(darwin, &quot;darwin&quot;) darwin_data ## # A tibble: 76,710 × 2 ## word novel ## &lt;chr&gt; &lt;chr&gt; ## 1 origin darwin ## 2 species darwin ## 3 charles darwin ## 4 darwin darwin ## 5 historical darwin ## 6 sketch darwin ## 7 progress darwin ## 8 opinion darwin ## 9 origin darwin ## 10 species darwin ## # … with 76,700 more rows Now we have transformed the data into a tidy dataframe with two columns: word and novel. Note that there are currently 78,556 rows of words – this number will significantly reduce once the lexicon analysis is applied as we will later explain. 2.3.1 Initial Analysis: Wordclouds Before analyzing the sentiment of the novel, we can start an initial analysis of the words based on their frequency within the text. This allows us to gain some initial insight into patterns we might want to explore later. We can easily create word clouds via the worldcloud package which is facilitated by our tidy data. Word clouds are a descriptive tool and should only be used to capture basic qualitative insights at initial stages of analysis. They present text data in a simple and clear format where the cloud size of a word depends on their respective frequencies. They are visually easy and quick to understand. library(RColorBrewer) # color palettes library(wordcloud) # word-cloud generator darwin_wordcloud &lt;- darwin_data %&gt;% count(word) %&gt;% with(wordcloud(word, n, max.words = 100, colors=brewer.pal(8, &quot;Dark2&quot;))) Figure 2.1: The most common words in Darwin’s novel darwin_wordcloud ## NULL As expected, a scientific book about evolution such as “The Origin of Species” contains frequent words like species, selection, and natural. Given the scientific nature of this book, the amount of rows of our data is expected to drop significantly since the lexicons only contain specific words that contain sentimental classification. 2.3.2 Sentiment Analysis: Lexicon Application Once tidy text is obtained, we can proceed to apply a sentiment lexicon by using inner_join() from the dpylr package. In this section we will: Explore the sentiment lexicons and their word counts Identify how many words from the book exist in the lexicons Look at specific words and word forms 2.3.2.1 Creating Sentiment Datasets Below we created data sets based on specific lexicons. This will facilitate our visualizations in the following sections. # afinn dataset darwin_afinn &lt;- darwin_data %&gt;% inner_join(get_sentiments(&quot;afinn&quot;)) nrow(darwin_afinn) ## [1] 4639 # bing dataset darwin_bing &lt;- darwin_data %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) nrow(darwin_bing) ## [1] 6210 # nrc dataset darwin_nrc &lt;- darwin_data %&gt;% inner_join(get_sentiments(&quot;nrc&quot;)) nrow(darwin_nrc) ## [1] 26394 As predicted, the number of rows reduced after each lexicon was applied. The afinn lexicon significantly reduced the row dimensions from 78,556 rows of words to 4,758. The bing lexicon resulted in 6,378 rows whereas the nrc lexicon has the greatest amount at 27,156 rows. This may be due to its multi-categorical nature since it is able to encapsulate more words. 2.4 Most Common Words Since we have a tidy dataframe, we can easily display the most common positive and negative words. This is done by analyzing word counts that contribute to each sentiment. By implementing count() with arguments of both word and sentiment, we find out each word’s sentimental contribution. afinn_word_counts &lt;- darwin_afinn %&gt;% #summarise(sentiment = sum(value)) %&gt;% mutate(method = &quot;AFINN&quot;) %&gt;% count(word, sentiment = value, sort = TRUE) afinn_word_counts ## # A tibble: 544 × 3 ## word sentiment n ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 natural 1 491 ## 2 doubt -1 106 ## 3 perfect 3 100 ## 4 importance 2 90 ## 5 increase 1 80 ## 6 struggle -2 80 ## 7 true 2 79 ## 8 advantage 2 72 ## 9 chance 2 64 ## 10 improved 2 62 ## # … with 534 more rows Now we will count the darwin_bing data set which assigns a binary classification of positive and negative sentiment. bing_word_counts &lt;- darwin_bing %&gt;% count(word, sentiment, sort = TRUE) %&gt;% ungroup() bing_word_counts ## probably dont need to display ## # A tibble: 995 × 3 ## word sentiment n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 doubt negative 106 ## 2 perfect positive 100 ## 3 difficulty negative 96 ## 4 variety positive 93 ## 5 struggle negative 80 ## 6 respect positive 77 ## 7 slowly negative 74 ## 8 advantage positive 72 ## 9 complex negative 68 ## 10 improved positive 62 ## # … with 985 more rows Similarly, we count darwin_nrc data set which contains multiple categories of sentiment. nrc_word_counts &lt;- darwin_nrc %&gt;% count(word, sentiment, sort = TRUE) %&gt;% ungroup() nrc_word_counts ## # A tibble: 2,990 × 3 ## word sentiment n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 structure positive 243 ## 2 structure trust 243 ## 3 time anticipation 236 ## 4 degree positive 206 ## 5 found joy 166 ## 6 found positive 166 ## 7 found trust 166 ## 8 organic positive 160 ## 9 theory anticipation 155 ## 10 theory trust 155 ## # … with 2,980 more rows 2.5 Visualizations Now that we have the word counts of the data set with respect to each lexicon, we can start visualizing the text to see the most common positive and negative words. By doing so, we can see the contribution of certain words based on their sentiment contribution within the text. 2.5.1 Positive - Bar Chart with Afinn Using the afinn_word_counts variable we can use the mutate() to create a new variable known as sentiment_severity which accounts for the sentiment contribution of a word based on the its frequency appearance and score. Using ggplot2 we can visually see the contribution that each common positive (score &gt;= 0) and negative (score &lt; 0) word had with respect to sentiment. afinn_plot &lt;- afinn_word_counts %&gt;% mutate(sentiment_severity = sentiment * n) %&gt;% slice_max(n, n = 10) %&gt;% ungroup() %&gt;% mutate(word = reorder(word, n)) %&gt;% ggplot(aes(sentiment_severity, word, fill = sentiment_severity)) + geom_col(stat=&quot;identity&quot;) + labs(x = &quot;Contribution to sentiment&quot;, y = &quot;Most Contributing Words&quot;, fill = &quot;Sentiment Severity Score&quot;) + ggtitle(&quot;Charles Darwin Afinn Sentiment&quot;) afinn_plot Figure 2.2: Afinn Words that contribute to positive and negative sentiment in Darwin’s Novel Based on the legend, a sentiment severity score closer to 400 will indicate a word that is most frequent and most positive within the text. A negative sentiment severity score closer to zero will indicate a word that is least frequent and most negative within the text. 2.5.2 Wordclouds with Bing We can further analyze wordclouds with sentiment analysis using the comparison.cloud() function where our current dataframe must be turned into a matrix via acast() which is located in the reshape2’s. Now we can conduct sentiment analysis using a inner_join on positive and negative words via the bing lexicon which is already incorporated within bing_word_counts. library(reshape2) bing_wc_plot &lt;- bing_word_counts %&gt;% acast(word ~ sentiment, value.var = &quot;n&quot;, fill = 0) %&gt;% comparison.cloud(colors = c(&quot;red&quot;, &quot;dark green&quot;), max.words = 100) Figure 2.3: Bing Words that contribute to positive and negative sentiment in Darwin’s Novel bing_wc_plot ## NULL The above word cloud illustrates the words that are most and least common within the text based on frequency. The larger the word the more frequent and the smaller the word then the least frequent. Unlike the word cloud previously generated in figure 1, this one allows us to classify between positive and negative words since we applied comparison.cloud() function to the variable bing_word_counts. This word cloud enables us to efficiently visualize the negative (red words) as well as positive groups (green words) of data. The above plot shows that words like doubt have a heavy presence that leans towards negative sentiment whereas words like favour are not as prevalent and tend to be more positive. 2.5.3 Bar Graph with NRC The plot below shows the total number of instances of words in the text, associated with each of the ten emotions. Using the ggplolt() function we can easily plot the word counts of words that are classified based on the the NRC lexicon which contains multiple categories. nrc_plot &lt;- darwin_nrc %&gt;% group_by(sentiment) %&gt;% summarise(word_count = n()) %&gt;% ungroup() %&gt;% mutate(sentiment = reorder(sentiment, word_count)) %&gt;% ggplot(aes(sentiment, word_count, fill = sentiment)) + geom_col() + labs(x = &quot;Sentiment Categories&quot;, y = &quot;Word Count&quot;) + ggtitle(&quot;Charles Darwin NRC Sentiment&quot;) nrc_plot Figure 2.4: NRC Words that contribute to categorical sentiment in Darwin’s Novel This bar chart demonstrates that positively oriented words categorized under positive are about 6 times more likely to appear within the text in comparison to disgust words. In general, the negatively oriented words are much less frequent. 2.6 Summary In this tutorial, we went through a simplified sentiment analysis project in R that was implemented over the dataset of Charles Darwin’s book entitled “The Origin of Species.” We started by transforming the data into tidy data by using packages such as tidytext and dpylr. When text data is in a tidy data structure then we can implement sentiment analysis using inner_join()in conjunction with a specified lexicon. We then proceeded to get the most common positive and negative words within the text along with its sentiment contribution. In conclusion, we used sentiment analysis to understand what words are important based on emotional and opinion content by exploring visualizations. 2.7 References Mohammad, Saif M, and Peter D Turney. 2013. “Crowdsourcing a Word-Emotion Association Lexicon.” Computational Intelligence 29 (3): 436–65. Schweinberger, Martin. (2022)` Sentiment Analysis in R. Brisbane: The University of Queensland. url: https://ladal.edu.au/sentiment.html (Version 2022.10.30). Silge, Julia, and David Robinson. 2017. Text Mining with r: A Tidy Approach. ” O’Reilly Media, Inc.”. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
